{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import kaggle\n",
    "\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess files from raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common-mobile-web-app-icons.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files(dataset_name, path=raw_data_dir, unzip=True, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of files and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = [f.name for f in os.scandir(raw_data_dir) if f.is_dir()]\n",
    "\n",
    "files = []\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(raw_data_dir, subdir)\n",
    "    files += [os.path.join(subdir_path, f.name) for f in os.scandir(subdir_path) if f.is_file()]\n",
    "\n",
    "# Remove not images from dataset\n",
    "not_jpg = [f for f in files if not f.endswith(\".jpg\")]\n",
    "files = [file for file in files if file not in not_jpg]\n",
    "\n",
    "# Sort files to maintain order\n",
    "files = sorted(files)\n",
    "\n",
    "labels = [file.split(\"\\\\\")[-2] for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = dict((label, index) for index, label in enumerate(sorted(set(labels))))\n",
    "encoded_labels = [label2index[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split files into training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_FILES  = len(files)\n",
    "NUMBER_OF_LABELS = len(label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(files,\n",
    "                                                                      encoded_labels,\n",
    "                                                                      test_size=TEST_SPLIT_FACTOR,\n",
    "                                                                      random_state=1969)\n",
    "\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(train_files,\n",
    "                                                                    train_labels,\n",
    "                                                                    test_size=VAL_SPLIT_FACTOR,\n",
    "                                                                    random_state=1969)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare images in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = tf.image.encode_jpeg(\n",
    "        image,\n",
    "        optimize_size=True,\n",
    "        x_density=96,\n",
    "        y_density=96\n",
    "    )\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_and_prepare_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return prepare_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "test_images_ds  = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "val_images_ds   = tf.data.Dataset.from_tensor_slices(val_files)\n",
    "\n",
    "train_labels_ds = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "test_labels_ds  = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "val_labels_ds   = tf.data.Dataset.from_tensor_slices(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply preprocessing to images datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = train_images_ds.map(load_and_prepare_image, num_parallel_calls=4)\n",
    "test_images_ds  =  test_images_ds.map(load_and_prepare_image, num_parallel_calls=4)\n",
    "val_images_ds   =   val_images_ds.map(load_and_prepare_image, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images datasets to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_ds = train_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "test_images_ds  =  test_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "val_images_ds   =   val_images_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "\n",
    "train_writer = tf.data.experimental.TFRecordWriter(train_images_file)\n",
    "test_writer  = tf.data.experimental.TFRecordWriter( test_images_file)\n",
    "val_writer   = tf.data.experimental.TFRecordWriter(  val_images_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Do not use the commented code below!!!</span>\n",
    "### ...unless you're 100% sure you know why are you doing this\n",
    "This will override our dataset and it will be no longer consistent with a previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_writer.write(train_images_ds)\n",
    "# test_writer. write(test_images_ds)\n",
    "# val_writer.  write(val_images_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save labels datasets to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ds = train_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "test_labels_ds  =  test_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "val_labels_ds   =   val_labels_ds.map(tf.io.serialize_tensor, num_parallel_calls=4)\n",
    "\n",
    "train_writer = tf.data.experimental.TFRecordWriter(train_labels_file)\n",
    "test_writer  = tf.data.experimental.TFRecordWriter( test_labels_file)\n",
    "val_writer   = tf.data.experimental.TFRecordWriter(  val_labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Do not use the commented code below!!!</span>\n",
    "### ...unless you're 100% sure you know why are you doing this\n",
    "This will override our dataset and it will be no longer consistent with a previous version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_writer.write(train_labels_ds)\n",
    "# test_writer. write(test_labels_ds)\n",
    "# val_writer.  write(val_labels_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2-gpu]",
   "language": "python",
   "name": "conda-env-tf2-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
